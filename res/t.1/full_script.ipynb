{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Routing Between Capsules\n",
    "\n",
    "Link: https://arxiv.org/abs/1710.09829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor as tt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "# Get matplotlib configuration\n",
    "%run plot_conf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_one_hot(index_tensor, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts index value to one hot vector.\n",
    "\n",
    "    e.g. [2, 5] (with 10 classes) becomes:\n",
    "        [\n",
    "            [0 0 1 0 0 0 0 0 0 0]\n",
    "            [0 0 0 0 1 0 0 0 0 0]\n",
    "        ]\n",
    "    \"\"\"\n",
    "    index_tensor = index_tensor.long()\n",
    "    return torch.eye(num_classes).index_select(dim=0, index=index_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squashing function\n",
    "\n",
    "$$\\boldsymbol{v}_j = {\\lVert\\boldsymbol{s}_j\\rVert^2 \\over 1 + \\lVert\\boldsymbol{s}_j\\rVert^2} {\\boldsymbol{s}_j \\over \\lVert\\boldsymbol{s}_j\\rVert}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash_vector(tensor, dim=-1):\n",
    "    \"\"\"\n",
    "    Non-linear 'squashing' to ensure short vectors get shrunk\n",
    "    to almost zero length and long vectors get shrunk to a\n",
    "    length slightly below 1.\n",
    "    \"\"\"\n",
    "    squared_norm = (tensor**2).sum(dim=dim, keepdim=True)\n",
    "    scale = squared_norm / (1 + squared_norm)\n",
    "    return scale * tensor / torch.sqrt(squared_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(input, dim=1):\n",
    "    \"\"\"\n",
    "    Apply softmax to specific dimensions. Not released on PyTorch stable yet\n",
    "    as of 19th November 2017\n",
    "    https://github.com/pytorch/pytorch/issues/3235\n",
    "    \"\"\"\n",
    "    transposed_input = input.transpose(dim, len(input.size()) - 1)\n",
    "    softmaxed_output = F.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)))\n",
    "    return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(input.size()) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self, num_capsules, num_routes, in_channels, out_channels,\n",
    "                 kernel_size=None, stride=None, num_iterations=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_routes = num_routes\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "        self.num_capsules = num_capsules\n",
    "\n",
    "        if num_routes != -1:\n",
    "            self.route_weights = nn.Parameter(torch.randn(num_capsules, num_routes, in_channels, out_channels))\n",
    "\n",
    "        else:\n",
    "            self.capsules = nn.ModuleList([\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=0)\n",
    "                for _ in range(num_capsules)\n",
    "            ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # If routing is defined\n",
    "        if self.num_routes != -1:\n",
    "            priors = x[None, :, :, None, :] @ self.route_weights[:, None, :, :, :]\n",
    "\n",
    "            logits = Variable(torch.zeros(priors.size())).type_as(x)\n",
    "\n",
    "            # Routing algorithm\n",
    "            for i in range(self.num_iterations):\n",
    "                probs = softmax(logits, dim=2)\n",
    "                outputs = squash_vector(probs * priors).sum(dim=2, keepdim=True)\n",
    "\n",
    "                if i != self.num_iterations - 1:\n",
    "                    delta_logits = (priors * outputs).sum(dim=-1, keepdim=True)\n",
    "                    logits = logits + delta_logits\n",
    "\n",
    "        else:\n",
    "            outputs = [capsule(x).view(x.size(0), -1, 1) for capsule in self.capsules]\n",
    "            outputs = torch.cat(outputs, dim=-1)\n",
    "            outputs = squash_vector(outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n",
    "        self.primary_capsules = CapsuleLayer(8, -1, 256, 32, kernel_size=9, stride=2)\n",
    "\n",
    "        # 10 is the number of classes\n",
    "        self.digit_capsules = CapsuleLayer(10, 32 * 6 * 6, 8, 16)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16 * 10, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = F.relu(self.conv1(x), inplace=True)\n",
    "        x = self.primary_capsules(x)\n",
    "        x = self.digit_capsules(x).squeeze().transpose(0, 1)\n",
    "\n",
    "        classes = (x ** 2).sum(dim=-1) ** 0.5\n",
    "\n",
    "        if y is None:\n",
    "            # In all batches, get the most active capsule\n",
    "            _, max_length_indices = classes.max(dim=1)\n",
    "            y = Variable(torch.eye(10)).type_as(x).index_select(dim=0, index=max_length_indices.data)\n",
    "\n",
    "        reconstructions = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n",
    "        return classes, reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Margin loss\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{k}^{(i)} =\n",
    "\\begin{cases}\n",
    "\\left[ \\left( {m_+} - \\lVert {\\boldsymbol{v}_k^{(i)}} \\rVert \\right)^+ \\right]^2,& \\text{digit } {k} \\text{ preset}\\\\\n",
    "\\lambda \\left[ \\left( \\lVert {\\boldsymbol{v}_k^{(i)}} \\rVert - {m_-} \\right)^+ \\right]^2,& \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_\\mu^{(i)} = \\sum_{k}\\mathcal{L}_{k}^{(i)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}^{(i)} = \\mathcal{L}_\\mu^{(i)} + \\rho \\cdot \\mathcal{L}_\\rho^{(i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginLoss(nn.Module):\n",
    "    def __init__(self, m_plus=0.9, m_minus=0.1, rho=0.0005):\n",
    "        super().__init__()\n",
    "        self.m_plus = m_plus\n",
    "        self.m_minus = m_minus\n",
    "        self.rho = rho\n",
    "        # Reconstruction as regularization\n",
    "        self.reconstruction_loss = nn.MSELoss(size_average=False)\n",
    "\n",
    "    def forward(self, images, labels, classes, reconstructions):\n",
    "        left = F.relu(self.m_plus - classes, inplace=True) ** 2\n",
    "        right = F.relu(classes - self.m_minus, inplace=True) ** 2\n",
    "        margin_loss = labels * left + 0.5 * (1. - labels) * right\n",
    "        margin_loss = margin_loss.sum()\n",
    "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n",
    "\n",
    "        return (margin_loss + self.rho * reconstruction_loss) / images.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Globals\n",
    "CUDA = True\n",
    "EPOCH = 10\n",
    "\n",
    "# Model\n",
    "model = CapsuleNet()\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "margin_loss = MarginLoss()\n",
    "\n",
    "train_MNIST  = MNIST(root='/tmp', train=True, download=True, transform=tt())\n",
    "train_loader = DataLoader(train_MNIST, batch_size=16, shuffle=True)\n",
    "test_MNIST   = MNIST(root='/tmp', train=False, download=True, transform=tt())\n",
    "test_loader  = DataLoader(test_MNIST, batch_size=16, shuffle=True)\n",
    "\n",
    "plt_interactive()\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Accuracy', color='C2')\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Running training loss')\n",
    "ax.set_xlim([-100, len(train_loader) + 100])\n",
    "\n",
    "train_avg_loss = list()\n",
    "test_avg_loss = list()\n",
    "test_accuracy = list()\n",
    "lines = None\n",
    "\n",
    "for e in range(10):\n",
    "    # Training\n",
    "    train_loss_running = list()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for idx, (img, target) in enumerate(train_loader):\n",
    "        img = Variable(img)\n",
    "        target = Variable(index_to_one_hot(target))\n",
    "\n",
    "        if CUDA:\n",
    "            img = img.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        classes, reconstructions = model(img, target)\n",
    "\n",
    "        loss = margin_loss(img, target, classes, reconstructions)\n",
    "        loss.backward()\n",
    "\n",
    "        train_loss += loss.data.cpu()[0]\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_running.append(loss.data[0])\n",
    "        if lines: lines.pop(0).remove()\n",
    "        lines, _ = ax.plot(train_loss_running, 'C0'), plt.gcf().canvas.draw()\n",
    "\n",
    "#     print('Training:, Avg Loss: {:.4f}'.format(train_loss))\n",
    "    train_avg_loss.append(train_loss)\n",
    "    ax1.plot(train_avg_loss, '-oC0')\n",
    "\n",
    "    # # Testing\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    for idx, (img, target) in enumerate(test_loader):\n",
    "        img = Variable(img)\n",
    "        target_index = target\n",
    "        target = Variable(index_to_one_hot(target))\n",
    "\n",
    "        if CUDA:\n",
    "            img = img.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        classes, reconstructions = model(img, target)\n",
    "\n",
    "        test_loss += margin_loss(img, target, classes, reconstructions).data.cpu()\n",
    "\n",
    "        # Get index of the max log-probability\n",
    "        pred = classes.data.max(1, keepdim=True)[1].cpu()\n",
    "        correct += pred.eq(target_index.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    correct = 100. * correct / len(test_loader.dataset)\n",
    "#     print('Test Set: Avg Loss: {:.4f}, Accuracy: {:.4f}'.format(test_loss[0], correct))\n",
    "    test_avg_loss.append(test_loss[0])\n",
    "    test_accuracy.append(correct)\n",
    "    ax1.plot(test_avg_loss, '-oC1')\n",
    "    ax2.plot(test_accuracy, '-oC2')\n",
    "    ax1.legend(['Training loss', 'Testing loss'], loc=0)\n",
    "    ax2.legend(['Test accuracy'], loc=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
